# -*- coding: utf-8 -*-
"""movie recommendation system main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cfAmQEeXphAA5IQPRgU9PvRss6lIK9Y_
"""

import pandas as pd
import numpy as np

movies = pd.read_csv('/content/tmdb_5000_movies.csv')

credits = pd.read_csv('/content/tmdb_5000_credits.csv')

"""Data preprocessing"""

movies.head(1)

"""## **Taking out values of cast from credit dataframe**"""

credits.head(1)['cast'].values

"""merging credit and movies dataframe with the help of title"""

movies = movies.merge(credits,on = 'title')

movies.shape

"""columns which will be used -:
#genres
#id
#keywords
#title
#overview
#cast
#crew














"""

movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]

"""counting values of original language"""

movies.info()

movies.head()

movies.isnull().sum()

"""removing nan values in overvie"""

movies.dropna(inplace = True)

movies.isnull().sum()

"""checking duplicated values"""

movies.duplicated().sum()

"""taking out genres column details"""

movies.iloc[0].genres

import ast

def clean(x):
  L = []
  for i in ast.literal_eval(x):
    L.append(i["name"])
  return L

movies['genres'] = movies['genres'].apply(clean)

movies['keywords'] = movies['keywords'].apply(clean)

movies.head()

def clean3(x):
  L = []
  counter = 0
  for i in ast.literal_eval(x):
    if counter!=3:
         L.append(i["name"])
    else:
      break
  return L

movies['cast'] = movies['cast'].apply(clean3)

movies.head()

def director(x):
  L = []
  for i in ast.literal_eval(x):
    if i["job"]== "Director":
      L.append(i["name"])
      break
  return L

movies['crew'] = movies['crew'].apply(director)

movies.head()

movies.iloc[0].overview

"""converting string into list using lamda and split function"""

movies.head()

movies['overview']=movies['overview'].apply(lambda x:x.split())

"""\**Removing space between two words**"""

movies['genres']=movies['genres'].apply(lambda x:[i.replace(" " , "") for i in x])
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" " , "") for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" " , "") for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" " , "") for i in x])

movies.head()

"""new column by name tags"""

movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

movies.head()

"""creating new data frame by the name new_df"""

new_df_movies = movies[['movie_id','title','tags']]

new_df_movies.head()

"""converting tags data into string"""

new_df_movies['tags'] = new_df_movies['tags'].apply(lambda x:" ".join(x))

new_df_movies.head()

"""#importing nltk library for stemming process





"""

import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

"""# helper function"""

def stemmer(text):
  y = []
  for i in text.split():
    y.append(ps.stem(i))

  return " ".join(y)

new_df_movies['tags'] = new_df_movies['tags'].apply(stemmer)

"""converting tags data into lower case"""

new_df_movies['tags'][0]

new_df_movies['tags'] = new_df_movies['tags'].apply(lambda x:x.lower())

new_df_movies.head()

"""

# VECTORIZATION


"""

from sklearn.feature_extraction.text import CountVectorizer
countv = CountVectorizer(max_features = 50000, stop_words = 'english')

"""converting countvector object into numpy array"""

vectors = countv.fit_transform(new_df_movies['tags']).toarray()

countv.fit_transform(new_df_movies['tags']).toarray().shape

vectors[0]

countv.get_feature_names_out()

"""# similarity beteen movies by using cosine similarity"""

from sklearn.metrics.pairwise import  cosine_similarity

similarity = cosine_similarity(vectors)

sorted(list(enumerate(similarity[0])), reverse = True , key = lambda x:x[1])[1:11]

def recommender(movie):
  movie_index = new_df_movies[new_df_movies["title"]==movie].index[0]
  distance = similarity[movie_index]
  movie_list = sorted(list(enumerate(distance)), reverse = True , key = lambda x:x[1])[1:11]

  for i in movie_list:
    print(new_df_movies.iloc[i[0]].title)

recommender('Spectre')

"""# pickling"""

import pickle

pickle.dump(new_df_movies,open('movies.pkl','wb'))

new_df_movies['title'].values

"""# converting dataframe into dictionary"""

pickle.dump(new_df_movies.to_dict() , open('movies_dict.pkl' , 'wb'))

pickle.dump(similarity , open('similarity.pkl' , 'wb'))